{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca39772e-3ac4-4d38-8d05-f45d8354b7b6",
   "metadata": {},
   "source": [
    "# Spatial Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07f3ad-610d-48ef-ad7e-ce7a03f7e8bb",
   "metadata": {},
   "source": [
    "We run this on the latest official RAPIDS container (on a NVIDIA GPU accelerated machine), which we can launch with:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all --rm -it \\\n",
    "    -p 8889:8888 -p 8788:8787 -p 8786:8786 \\\n",
    "    -v /media/dani/DataStore/data/:/rapids/notebooks/data \\\n",
    "    -v ${PWD}:/rapids/notebooks/work \\\n",
    "    rapidsai/rapidsai:cuda11.4-runtime-ubuntu20.04-py3.9\n",
    "```\n",
    "\n",
    "With this setup, we can access the same `work` and `data` folders as in the [previous notebook](data_acquisition.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2a765c-c96d-4b23-b6ef-a5c30fcb2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import cuspatial\n",
    "import pandas\n",
    "from tools import sjoin_gpu\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "\n",
    "uprn_p = '/rapids/notebooks/data/tmp/epc_uprn.pq'\n",
    "ss_p = '/rapids/notebooks/data/tmp/sss.pq'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab279f0-c2d5-4e44-b204-c141ee5f0fbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Check GPU-based spatial join validity\n",
    "\n",
    "Before we run the spatial join on the whole dataset, and since `cuspatial` is a relatively new library compared to `geopandas`, we perform a check on a small sample to confirm the results from the spatial join are the same.\n",
    "\n",
    "We will read into RAM the first 1,600 EPC properties (`uprn`) and joined them to the spatial signature polygons (`ss`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df14cfb3-9d9e-4834-b9be-05214aa83805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 s, sys: 7.68 s, total: 32.2 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn = geopandas.read_parquet(uprn_p).head(1600)\n",
    "ss = geopandas.read_parquet(ss_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56667881-428a-43a9-b0d9-4dfcab05c148",
   "metadata": {},
   "source": [
    "Then we move them to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df07b783-01b0-42e2-95b5-3f788f727593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.78 s, sys: 675 ms, total: 8.45 s\n",
      "Wall time: 8.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn_gpu = cuspatial.from_geopandas(uprn)\n",
    "ss_gpu = cuspatial.from_geopandas(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196fdbb-31fc-45c7-af4f-94f88ca01833",
   "metadata": {},
   "source": [
    "And perform the GPU-backed spatial join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8934cd-ccc0-4deb-b8f9-0a6d8c36fd26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/cuspatial/core/spatial/indexing.py:193: UserWarning: scale 5 is less than required minimum scale 9345.561538461538. Clamping to minimum scale\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/cuspatial/core/spatial/join.py:171: UserWarning: scale 5 is less than required minimum scale 9345.561538461538. Clamping to minimum scale\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 649 ms, sys: 40.1 ms, total: 689 ms\n",
      "Wall time: 686 ms\n"
     ]
    }
   ],
   "source": [
    "%time tst_gpu = sjoin_gpu(uprn_gpu, ss_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febae7c0-4b51-4920-9e89-e8a2823085c8",
   "metadata": {},
   "source": [
    "And the same with `geopandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66b5aa3-9dd2-44b5-9fe0-08aa86577d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 s, sys: 757 Âµs, total: 1.78 s\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tst = geopandas.sjoin(uprn, ss, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeffae1-89ed-40c8-877a-8fa8ad20a55a",
   "metadata": {},
   "source": [
    "We can see computation time is much shorter on the GPU (this gap actually grows notably when the number of points grows, to obtain at least a 20x performance boost). To compare the two results, we join them into a single table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8251a34-162f-4efb-8c5b-a93466c843e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = tst.join(\n",
    "    tst_gpu.to_pandas().set_index('LMK_KEY'), \n",
    "    on='LMK_KEY', \n",
    "    rsuffix='_gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c072c0b-141d-4076-b30e-b30ddf8060b7",
   "metadata": {},
   "source": [
    "And check that the unique identifier of each EPC property (`id` and `id_gpu`) are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1023f829-279b-44af-a382-68ebcf1fa8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(check['id'] != check['id_gpu']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e1fa4-d2a3-4ad3-a304-dc335659a723",
   "metadata": {},
   "source": [
    "The only instance in this sample that differs actually doesn't differ but it is a point that is not joined to any polygon and hence has `NaN` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160db435-e256-4ec8-8ac3-dc05d0156c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMK_KEY</th>\n",
       "      <th>CONSTRUCTION_AGE_BAND</th>\n",
       "      <th>UPRN</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>type</th>\n",
       "      <th>point_index</th>\n",
       "      <th>UPRN_gpu</th>\n",
       "      <th>CONSTRUCTION_AGE_BAND_gpu</th>\n",
       "      <th>id_gpu</th>\n",
       "      <th>type_gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>887304392732013022216585817278109</td>\n",
       "      <td>England and Wales: 2007 onwards</td>\n",
       "      <td>10090070569</td>\n",
       "      <td>POINT (452546.000 533673.000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               LMK_KEY            CONSTRUCTION_AGE_BAND  \\\n",
       "559  887304392732013022216585817278109  England and Wales: 2007 onwards   \n",
       "\n",
       "            UPRN                       geometry  index_right   id code type  \\\n",
       "559  10090070569  POINT (452546.000 533673.000)          NaN  NaN  NaN  NaN   \n",
       "\n",
       "     point_index UPRN_gpu CONSTRUCTION_AGE_BAND_gpu id_gpu type_gpu  \n",
       "559          NaN      NaN                       NaN    NaN      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[check.eval('id != id_gpu')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f85ba0e-3695-4c11-b61b-6970490f1420",
   "metadata": {},
   "source": [
    "With this, we confirm we can use the GPU-backed spatial join, and proceed to deployment to the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6db08-10e4-426b-9166-3d34f317a690",
   "metadata": {},
   "source": [
    "## Join UPRNs to Spatial Signatures on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4731d-5b97-4ba1-80f3-19e6105718f3",
   "metadata": {},
   "source": [
    "We read in RAM the two tables without subsetting this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0f6532-14cd-4e91-9c21-7f8c25110ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.7 s, sys: 7.48 s, total: 32.1 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn = geopandas.read_parquet(uprn_p)\n",
    "ss = geopandas.read_parquet(ss_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da33139-a1c3-448b-8570-384a5c9e6d4e",
   "metadata": {},
   "source": [
    "Then we move them to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963769c8-4eeb-4432-a425-40981a59ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 46s, sys: 6.65 s, total: 3min 52s\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn_gpu = cuspatial.from_geopandas(uprn)\n",
    "ss_gpu = cuspatial.from_geopandas(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fd625-6780-4494-ab8b-0e43b5f5e0ce",
   "metadata": {},
   "source": [
    "And we are ready to perform the GPU-backed spatial join. Because the GPU on which this is being run only has 8GB or memory, we need to chunk the computation. We will do this by joining `chunk_size` points at a time and storing the results back on RAM. Once finished, we save the resulting table to disk. \n",
    "\n",
    "We can set this up with a simple `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fc378-94d1-449e-b734-d96da6dd100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â         | 4/46 [01:16<13:06, 18.73s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = []\n",
    "chunk_size = 500000\n",
    "for i in tqdm(range(ceil(len(uprn_gpu) / chunk_size))):\n",
    "    chunk = uprn_gpu.iloc[i*(chunk_size-1): i*(chunk_size-1)+chunk_size, :]\n",
    "    sjoined = sjoin_gpu(chunk, ss_gpu, scale=10000)\n",
    "    out.append(sjoined.to_pandas())\n",
    "out = pandas.concat(out)\n",
    "out.to_parquet('/rapids/notebooks/data/tmp/epc_uprn_ss.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b208c8-1498-48ea-bdd1-d37f5fdf751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! du -h /rapids/notebooks/data/tmp/epc_uprn*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc2fde-6a80-4261-b6bb-eabb9c5fb585",
   "metadata": {},
   "source": [
    "## Method documentation\n",
    "\n",
    "Since the method used to perform the spatial join (`sjoin_gpu`) was written for this project, it might be helpful to print here its documentation:\n",
    "\n",
    "::: {.column-margin}\n",
    "You can download the file with the function [here](tools.py).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f79caa8-922e-40e8-ae34-894e0b2b7bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msjoin_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpts_gdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpoly_gdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpts_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LMK_KEY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UPRN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CONSTRUCTION_AGE_BAND'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpoly_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Spatial Join on a GPU\n",
       "...\n",
       "\n",
       "Adapted from:\n",
       "\n",
       "> https://docs.rapids.ai/api/cuspatial/stable/user_guide/users.html#cuspatial.quadtree_point_in_polygon\n",
       "\n",
       "Arguments\n",
       "---------\n",
       "pts_gdf : geopandas.GeoDataFrame/cuspatial.GeoDataFrame\n",
       "          Table with points\n",
       "poly_gdf : geopandas.GeoDataFrame/cuspatial.GeoDataFrame\n",
       "           Table with polygons\n",
       "scale : int\n",
       "        [From `cuspatial` docs. Default=5] A scaling function that increases the size of the point \n",
       "        space from an origin defined by `{x_min, y_min}`. This can increase the likelihood of \n",
       "        generating well-separated quads.\n",
       "        \n",
       "max_depth : int\n",
       "            [From `cuspatial` docs. Default=7] In order for a quadtree to index points effectively, \n",
       "            it must have a depth that is log-scaled with the size of the number of points. Each level \n",
       "            of the quad tree contains 4 quads. The number of available quads $q$\n",
       "            for indexing is then equal to $q = 4^d$ where $d$ is the max_depth parameter. With an input \n",
       "            size of 10m points and `max_depth` = 7, points will be most efficiently packed into the leaves\n",
       "            of the quad tree.\n",
       "max_size : int\n",
       "           [From `cuspatial` docs. Default=125] Maximum number of points allowed in a node before it's \n",
       "           split into 4 leaf nodes. \n",
       "pts_cols : list\n",
       "           [Optional. Default=['UPRN', 'CONSTRUCTION_AGE_BAND']] Column names in `pts_gdf` to be \n",
       "           joined in the output\n",
       "poly_cols : list\n",
       "            [Optional. Default=['id', 'type']] Column names in `poly_gdf` to be joined in the output \n",
       "\n",
       "Returns\n",
       "-------\n",
       "sjoined : cudf.DataFrame\n",
       "          Table with `pts_cols` and `poly_cols` spatially joined\n",
       "\u001b[0;31mFile:\u001b[0m      /rapids/notebooks/work/tools.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sjoin_gpu?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
