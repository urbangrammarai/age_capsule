{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca39772e-3ac4-4d38-8d05-f45d8354b7b6",
   "metadata": {},
   "source": [
    "# Spatial Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07f3ad-610d-48ef-ad7e-ce7a03f7e8bb",
   "metadata": {},
   "source": [
    "We run this on the latest official RAPIDS container (on a NVIDIA GPU accelerated machine), which we can launch with:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all --rm -it \\\n",
    "    -p 8889:8888 -p 8788:8787 -p 8786:8786 \\\n",
    "    -v /media/dani/DataStore/data/:/rapids/notebooks/data \\\n",
    "    -v ${PWD}:/rapids/notebooks/work \\\n",
    "    rapidsai/rapidsai:cuda11.4-runtime-ubuntu20.04-py3.9\n",
    "```\n",
    "\n",
    "With this setup, we can access the same `work` and `data` folders as in the [previous notebook](data_acquisition.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2a765c-c96d-4b23-b6ef-a5c30fcb2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import cuspatial\n",
    "import pandas\n",
    "from tools import sjoin_gpu\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "\n",
    "uprn_p = '/rapids/notebooks/data/tmp/epc_uprn.pq'\n",
    "ss_p = '/rapids/notebooks/data/tmp/sss.pq'\n",
    "pc_p = '/rapids/notebooks/data/tmp/postcode_pts.pq'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab279f0-c2d5-4e44-b204-c141ee5f0fbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Check GPU-based spatial join validity\n",
    "\n",
    "Before we run the spatial join on the whole dataset, and since `cuspatial` is a relatively new library compared to `geopandas`, we perform a check on a small sample to confirm the results from the spatial join are the same.\n",
    "\n",
    "We will read into RAM the first 1,600 EPC properties (`uprn`) and joined them to the spatial signature polygons (`ss`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df14cfb3-9d9e-4834-b9be-05214aa83805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.2 s, sys: 7.71 s, total: 34 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn = geopandas.read_parquet(uprn_p).head(1600)\n",
    "ss = geopandas.read_parquet(ss_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56667881-428a-43a9-b0d9-4dfcab05c148",
   "metadata": {},
   "source": [
    "Then we move them to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df07b783-01b0-42e2-95b5-3f788f727593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.78 s, sys: 675 ms, total: 8.45 s\n",
      "Wall time: 8.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn_gpu = cuspatial.from_geopandas(uprn)\n",
    "ss_gpu = cuspatial.from_geopandas(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196fdbb-31fc-45c7-af4f-94f88ca01833",
   "metadata": {},
   "source": [
    "And perform the GPU-backed spatial join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8934cd-ccc0-4deb-b8f9-0a6d8c36fd26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/cuspatial/core/spatial/indexing.py:193: UserWarning: scale 5 is less than required minimum scale 9345.561538461538. Clamping to minimum scale\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/cuspatial/core/spatial/join.py:171: UserWarning: scale 5 is less than required minimum scale 9345.561538461538. Clamping to minimum scale\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 649 ms, sys: 40.1 ms, total: 689 ms\n",
      "Wall time: 686 ms\n"
     ]
    }
   ],
   "source": [
    "%time tst_gpu = sjoin_gpu(uprn_gpu, ss_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febae7c0-4b51-4920-9e89-e8a2823085c8",
   "metadata": {},
   "source": [
    "And the same with `geopandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66b5aa3-9dd2-44b5-9fe0-08aa86577d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 s, sys: 757 µs, total: 1.78 s\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tst = geopandas.sjoin(uprn, ss, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeffae1-89ed-40c8-877a-8fa8ad20a55a",
   "metadata": {},
   "source": [
    "We can see computation time is much shorter on the GPU (this gap actually grows notably when the number of points grows, to obtain at least a 20x performance boost). To compare the two results, we join them into a single table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8251a34-162f-4efb-8c5b-a93466c843e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = tst.join(\n",
    "    tst_gpu.to_pandas().set_index('LMK_KEY'), \n",
    "    on='LMK_KEY', \n",
    "    rsuffix='_gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c072c0b-141d-4076-b30e-b30ddf8060b7",
   "metadata": {},
   "source": [
    "And check that the unique identifier of each EPC property (`id` and `id_gpu`) are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1023f829-279b-44af-a382-68ebcf1fa8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(check['id'] != check['id_gpu']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e1fa4-d2a3-4ad3-a304-dc335659a723",
   "metadata": {},
   "source": [
    "The only instance in this sample that differs actually doesn't differ but it is a point that is not joined to any polygon and hence has `NaN` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160db435-e256-4ec8-8ac3-dc05d0156c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMK_KEY</th>\n",
       "      <th>CONSTRUCTION_AGE_BAND</th>\n",
       "      <th>UPRN</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>type</th>\n",
       "      <th>point_index</th>\n",
       "      <th>UPRN_gpu</th>\n",
       "      <th>CONSTRUCTION_AGE_BAND_gpu</th>\n",
       "      <th>id_gpu</th>\n",
       "      <th>type_gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>887304392732013022216585817278109</td>\n",
       "      <td>England and Wales: 2007 onwards</td>\n",
       "      <td>10090070569</td>\n",
       "      <td>POINT (452546.000 533673.000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               LMK_KEY            CONSTRUCTION_AGE_BAND  \\\n",
       "559  887304392732013022216585817278109  England and Wales: 2007 onwards   \n",
       "\n",
       "            UPRN                       geometry  index_right   id code type  \\\n",
       "559  10090070569  POINT (452546.000 533673.000)          NaN  NaN  NaN  NaN   \n",
       "\n",
       "     point_index UPRN_gpu CONSTRUCTION_AGE_BAND_gpu id_gpu type_gpu  \n",
       "559          NaN      NaN                       NaN    NaN      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[check.eval('id != id_gpu')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f85ba0e-3695-4c11-b61b-6970490f1420",
   "metadata": {},
   "source": [
    "With this, we confirm we can use the GPU-backed spatial join, and proceed to deployment to the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6db08-10e4-426b-9166-3d34f317a690",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Join UPRNs to Spatial Signatures on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4731d-5b97-4ba1-80f3-19e6105718f3",
   "metadata": {},
   "source": [
    "We read in RAM the two tables without subsetting this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0f6532-14cd-4e91-9c21-7f8c25110ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.7 s, sys: 7.48 s, total: 32.1 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn = geopandas.read_parquet(uprn_p)\n",
    "ss = geopandas.read_parquet(ss_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da33139-a1c3-448b-8570-384a5c9e6d4e",
   "metadata": {},
   "source": [
    "Then we move them to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963769c8-4eeb-4432-a425-40981a59ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 46s, sys: 6.65 s, total: 3min 52s\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn_gpu = cuspatial.from_geopandas(uprn)\n",
    "ss_gpu = cuspatial.from_geopandas(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fd625-6780-4494-ab8b-0e43b5f5e0ce",
   "metadata": {},
   "source": [
    "And we are ready to perform the GPU-backed spatial join. Because the GPU on which this is being run only has 8GB or memory, we need to chunk the computation. We will do this by joining `chunk_size` points at a time and storing the results back on RAM. Once finished, we save the resulting table to disk. \n",
    "\n",
    "We can set this up with a simple `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fc378-94d1-449e-b734-d96da6dd100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 17/46 [06:55<13:08, 27.19s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = []\n",
    "chunk_size = 500000\n",
    "for i in tqdm(range(ceil(len(uprn_gpu) / chunk_size))):\n",
    "    chunk = uprn_gpu.iloc[i*(chunk_size-1): i*(chunk_size-1)+chunk_size, :]\n",
    "    sjoined = sjoin_gpu(chunk, ss_gpu, scale=10000)\n",
    "    out.append(sjoined.to_pandas())\n",
    "out = pandas.concat(out)\n",
    "out.to_parquet('/rapids/notebooks/data/tmp/epc_uprn_ss.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b208c8-1498-48ea-bdd1-d37f5fdf751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! du -h /rapids/notebooks/data/tmp/epc_uprn*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d48030-4dbc-4ffa-a543-689ac1a95dac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Join Postcode centroids to Spatial Signatures to Land Registry\n",
    "\n",
    "We replicate the approach above to join the centroid of each postcode to the spatial signature where they are located. For this, we first read into RAM both tables, postcode centroids and signature polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cb1c4b-171e-4001-a3c7-b0d5769f19fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 630 ms, sys: 211 ms, total: 841 ms\n",
      "Wall time: 742 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pc = geopandas.read_parquet(pc_p)\n",
    "ss = geopandas.read_parquet(ss_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642aa44-c044-43e7-ac87-28388bb6b786",
   "metadata": {},
   "source": [
    "Then we move them to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6041c83-d4b9-497c-a030-06ae79fe8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 516 ms, total: 11.6 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pc_gpu = cuspatial.from_geopandas(pc)\n",
    "ss_gpu = cuspatial.from_geopandas(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b64661-579d-4a6c-be94-2bf31050a36a",
   "metadata": {},
   "source": [
    "And we are ready to perform the GPU-backed spatial join. In this case, the dataset fits into the GPU all at once, so the code is greatly simplified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f403d27-3ff9-4c6f-98e8-c1713bbc9ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/cuspatial/core/spatial/indexing.py:193: UserWarning: scale 5 is less than required minimum scale 9345.561538461538. Clamping to minimum scale\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/cuspatial/core/spatial/join.py:171: UserWarning: scale 5 is less than required minimum scale 9345.561538461538. Clamping to minimum scale\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 104 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pc_ss = sjoin_gpu(\n",
    "    pc_gpu, ss_gpu, pts_cols=['PCD', 'lr_upc'], poly_cols=['id', 'type']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e757a-6c88-44c4-a867-c982dec9a3cc",
   "metadata": {},
   "source": [
    "Now we can bring back the table we prepared [earlier](data_acquisition.ipynb#land-registry-price-paid), attach signature types to each Land Registry sale, and write back to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0a025e1-3f27-4570-a6f5-3be36a14e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pandas.read_parquet(\n",
    "        '/rapids/notebooks/data/tmp/sales_by_month_pc.pq'\n",
    "    )\n",
    "    .join(\n",
    "        pc_ss.to_pandas()[['lr_upc', 'id', 'type']].set_index('lr_upc'),\n",
    "        on='postcode'\n",
    "    )\n",
    "    .dropna()\n",
    ").to_parquet('/rapids/notebooks/data/tmp/sales_by_month_pc_ss.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc2fde-6a80-4261-b6bb-eabb9c5fb585",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method documentation\n",
    "\n",
    "Since the method used to perform the spatial join (`sjoin_gpu`) was written for this project, it might be helpful to print here its documentation:\n",
    "\n",
    "::: {.column-margin}\n",
    "You can download the file with the function [here](tools.py).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f79caa8-922e-40e8-ae34-894e0b2b7bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msjoin_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpts_gdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpoly_gdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpts_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LMK_KEY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UPRN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CONSTRUCTION_AGE_BAND'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpoly_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Spatial Join on a GPU\n",
       "...\n",
       "\n",
       "Adapted from:\n",
       "\n",
       "> https://docs.rapids.ai/api/cuspatial/stable/user_guide/users.html#cuspatial.quadtree_point_in_polygon\n",
       "\n",
       "Arguments\n",
       "---------\n",
       "pts_gdf : geopandas.GeoDataFrame/cuspatial.GeoDataFrame\n",
       "          Table with points\n",
       "poly_gdf : geopandas.GeoDataFrame/cuspatial.GeoDataFrame\n",
       "           Table with polygons\n",
       "scale : int\n",
       "        [From `cuspatial` docs. Default=5] A scaling function that increases the size of the point \n",
       "        space from an origin defined by `{x_min, y_min}`. This can increase the likelihood of \n",
       "        generating well-separated quads.\n",
       "        \n",
       "max_depth : int\n",
       "            [From `cuspatial` docs. Default=7] In order for a quadtree to index points effectively, \n",
       "            it must have a depth that is log-scaled with the size of the number of points. Each level \n",
       "            of the quad tree contains 4 quads. The number of available quads $q$\n",
       "            for indexing is then equal to $q = 4^d$ where $d$ is the max_depth parameter. With an input \n",
       "            size of 10m points and `max_depth` = 7, points will be most efficiently packed into the leaves\n",
       "            of the quad tree.\n",
       "max_size : int\n",
       "           [From `cuspatial` docs. Default=125] Maximum number of points allowed in a node before it's \n",
       "           split into 4 leaf nodes. \n",
       "pts_cols : list\n",
       "           [Optional. Default=['UPRN', 'CONSTRUCTION_AGE_BAND']] Column names in `pts_gdf` to be \n",
       "           joined in the output\n",
       "poly_cols : list\n",
       "            [Optional. Default=['id', 'type']] Column names in `poly_gdf` to be joined in the output \n",
       "\n",
       "Returns\n",
       "-------\n",
       "sjoined : cudf.DataFrame\n",
       "          Table with `pts_cols` and `poly_cols` spatially joined\n",
       "\u001b[0;31mFile:\u001b[0m      /rapids/notebooks/work/tools.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sjoin_gpu?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
