{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9632b1-7518-4844-8999-321daaa3404f",
   "metadata": {},
   "source": [
    "# Data acquisition\n",
    "\n",
    "This document collates the three main datasets used int his capsule: the Energy Performance Certificates (EPC), the UPRN locations, and the Spatial Signature polygons. We first link (through a table join) building age, through EPC, with UPRN locations, and then we bring the Spatial Signatures. The two are subsequently joined on the GPU in a [separate notebook](gpu_spatial_join.ipynb). Each section details the origin of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88766125-b8d1-4cea-aea1-363a5182faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /opt/conda/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "from pyogrio import read_dataframe\n",
    "import warnings # To turn disable some known ones below\n",
    "\n",
    "uprn_p = '/home/jovyan/data/uk_os_openuprn/osopenuprn_202210.gpkg'\n",
    "epc_p = '/home/jovyan/data/uk_epc_certificates/'\n",
    "ss_p = '/home/jovyan/data/tmp/spatial_signatures_GB.gpkg'\n",
    "pp_p = '/home/jovyan/data/tmp/pp-complete.csv'\n",
    "pc_p = '/home/jovyan/data/tmp/postcodes.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38326a31-94cd-4184-9851-26af74d18c5e",
   "metadata": {},
   "source": [
    "Some of the computations will be run in parallel through Dask, so we set up a client for a local cluster with 16 workers (as many as threads in the machine where this is run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f30056-cf92-4dda-b1bb-15e555cacf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    client = Client(LocalCluster(n_workers=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286f4ab-e305-480e-90c5-920b3a8f7b2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## EPC certificates\n",
    "\n",
    "These need to be downloaded manually from the official website ([https://epc.opendatacommunities.org/](https://epc.opendatacommunities.org/)). Once unzipped, it is a collection of `.csv` files that can be processed efficiently with Dask. Here we specify the computation lazily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4ab8bf-1293-4417-8fa8-56ebf25f8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "   'CONSTRUCTION_AGE_BAND': 'str',\n",
    "   'UPRN': 'str',\n",
    "   'LMK_KEY': 'str'\n",
    "}\n",
    "certs_all = ddf.read_csv(\n",
    "    f'{epc_p}*/certificates.csv', \n",
    "    dtype=dtypes,\n",
    "    usecols=dtypes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6408fca-5196-466f-865c-fc3cef8a4c73",
   "metadata": {},
   "source": [
    "And execute it on the Dask cluster, local in this case, to load them in RAM (NOTE: this will take a significant amount of RAM on your machine). Note that we drop rows with `N/A` values in either of the three columns as we need observations with the three valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a0adc9-6399-48e9-9cfa-33a3eee37004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 3.1 s, total: 15.5 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    certs = certs_all.dropna().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274d167-094d-4285-b5da-7729e44af8c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UPRN coords\n",
    "\n",
    "UPRN coordinates are unique identifiers for property in Britain. We source them from the Ordnance Survey's Open UPRN product ([https://www.ordnancesurvey.co.uk/business-government/products/open-uprn](https://www.ordnancesurvey.co.uk/business-government/products/open-uprn)), which also needs to be downloaded manually. We access the GPKG format which contains the geometries created for each point already.\n",
    "\n",
    "To consume them, we load them up in RAM (NOTE - this will take a significant amount of memory on your machine):\n",
    "\n",
    "::: {.column-margin}\n",
    "The approach using `pyogrio` seems to beat a multi-core implementation with `dask-geopandas`, possibly because the latter relies on `geopandas.read_file`, even though it spreads the computation it across cores. In case of interest, here's the code:\n",
    "\n",
    "```python\n",
    "uprn = dask_geopandas.read_file(\n",
    "    uprn_p, npartitions=16\n",
    ").compute()\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d46285-3634-45ee-93a8-f97a9fa77f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.1 s, sys: 8.79 s, total: 1min 4s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uprn = read_dataframe(uprn_p, columns=['UPRN', 'geometry'])\n",
    "uprn['UPRN'] = uprn['UPRN'].astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459b1f5-0546-41e2-a95b-d67d03287262",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge UPRN-EPC\n",
    "\n",
    "With both tables ready in memory, we merge them so that we attach point geometries to all the EPC certificate points through their UPRNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7ca615-883c-4fe1-8b69-999a9bc1cc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.9 s, sys: 3.58 s, total: 44.4 s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = geopandas.GeoDataFrame(\n",
    "    certs.merge(\n",
    "        uprn, left_on='UPRN', right_on='UPRN', how='left'\n",
    "    ), crs=uprn.crs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a1f1e-7334-4af2-b8b9-6670c5751b9b",
   "metadata": {},
   "source": [
    "After the merge, we write the table to disk so it can be loaded later on for the spatial join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ddb431-f0dd-4674-95b3-7f46ea031e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3312797/3783868997.py:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  db.to_parquet('/home/jovyan/data/tmp/epc_uprn.pq')\n"
     ]
    }
   ],
   "source": [
    "db.to_parquet('/home/jovyan/data/tmp/epc_uprn.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adffb8b1-dde7-423e-a7ac-c7296b09d779",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spatial Signatures\n",
    "\n",
    "For the Spatial Signature boundaries, we rely on the official open data product. This can be downloaded programmatically from its [Figshare location](https://figshare.com/articles/dataset/Geographical_Characterisation_of_British_Urban_Form_and_Function_using_the_Spatial_Signatures_Framework/16691575/1). You can download it directly with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e7970e-8438-41e4-ba09-6f586157e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-21 17:30:16--  https://figshare.com/ndownloader/files/30904861\n",
      "Resolving figshare.com (figshare.com)... 54.194.88.49, 52.17.229.77, 2a05:d018:1f4:d003:376b:de5c:3a42:a610, ...\n",
      "Connecting to figshare.com (figshare.com)|54.194.88.49|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/30904861/spatial_signatures_GB.gpkg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20221221/eu-west-1/s3/aws4_request&X-Amz-Date=20221221T173017Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=6c7b771aaa9d3262e8c5d21388e81b74dd21b6d622d36a17bac818dc7fe6a71e [following]\n",
      "--2022-12-21 17:30:17--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/30904861/spatial_signatures_GB.gpkg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20221221/eu-west-1/s3/aws4_request&X-Amz-Date=20221221T173017Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=6c7b771aaa9d3262e8c5d21388e81b74dd21b6d622d36a17bac818dc7fe6a71e\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.85.75, 52.218.100.203, 52.92.1.232, ...\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.85.75|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 909824000 (868M) [application/octet-stream]\n",
      "Saving to: ‘/home/jovyan/data/tmp/spatial_signatures_GB.gpkg’\n",
      "\n",
      "/home/jovyan/data/t 100%[===================>] 867.68M  70.4MB/s    in 12s     \n",
      "\n",
      "2022-12-21 17:30:29 (72.6 MB/s) - ‘/home/jovyan/data/tmp/spatial_signatures_GB.gpkg’ saved [909824000/909824000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! rm -f $ss_p # Remove if exsisting\n",
    "! wget -O $ss_p https://figshare.com/ndownloader/files/30904861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc247f36-3af6-4326-baeb-19ebbf555f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 794 ms, total: 2.26 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ss = read_dataframe(ss_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed8d85-4c8a-420e-9177-c714c3e410fd",
   "metadata": {},
   "source": [
    "This is very detailed, which makes things much slower to run, so we simplify first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a91be2b-f3d5-4beb-8582-ba993c34ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 1.04 s, total: 1min 19s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sss = ss.simplify(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63285d4-ce92-4f4c-8918-701e12f99844",
   "metadata": {},
   "source": [
    "Now we can write to disk a Parquet table with the simplified geometries for consumption later in the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905b94dc-a4bf-4cfa-946b-027d31a372e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3312797/4276883947.py:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  ss.assign(geometry=sss).to_parquet('/home/jovyan/data/tmp/sss.pq')\n"
     ]
    }
   ],
   "source": [
    "ss.assign(geometry=sss).to_parquet('/home/jovyan/data/tmp/sss.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eaf454-9263-44ad-97d2-6e6e9d02f4d8",
   "metadata": {},
   "source": [
    "## Land Registry Price Paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54e0198-982f-44a3-80cd-58b95f2f395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-23 11:48:14--  http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv\n",
      "Resolving prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com (prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com)... 52.218.118.28, 52.218.120.108, 52.218.120.212, ...\n",
      "Connecting to prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com (prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com)|52.218.118.28|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://prod1.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv [following]\n",
      "--2022-12-23 11:48:14--  http://prod1.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv\n",
      "Resolving prod1.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com (prod1.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com)... 52.218.120.108, 52.218.120.212, 52.92.19.172, ...\n",
      "Reusing existing connection to prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4849144007 (4.5G) [text/csv]\n",
      "Saving to: ‘/home/jovyan/data/tmp/pp-complete.csv’\n",
      "\n",
      "/home/jovyan/data/t 100%[===================>]   4.52G  30.3MB/s    in 1m 47s  \n",
      "\n",
      "2022-12-23 11:50:02 (43.1 MB/s) - ‘/home/jovyan/data/tmp/pp-complete.csv’ saved [4849144007/4849144007]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget \\\n",
    "    http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv \\\n",
    "    -O $pp_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179d4c2-2303-49c3-976e-24c13538a28f",
   "metadata": {},
   "source": [
    "Following the [official documentation](https://www.gov.uk/guidance/about-the-price-paid-data#explanations-of-column-headers-in-the-ppd), the column names are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7b1c8b-59bc-4875-9143-069533acf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    'tid',\n",
    "    'price',\n",
    "    'date_of_transfer',\n",
    "    'postcode',\n",
    "    'property_type',\n",
    "    'new_build',\n",
    "    'duration',\n",
    "    'PAON',\n",
    "    'SAON',\n",
    "    'street',\n",
    "    'locality',\n",
    "    'town_city',\n",
    "    'district',\n",
    "    'county',\n",
    "    'ppd_cat_type',\n",
    "    'rec_status'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e721ebe-97cf-4aaa-b8ee-575d2847f4da",
   "metadata": {},
   "source": [
    "We only read a subset of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4afd573-efd1-4d72-84da-505b3f36939b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 3.32 s, total: 14.1 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pp = ddf.read_csv(\n",
    "    pp_p, \n",
    "    names=col_names,\n",
    "    usecols=['tid', 'date_of_transfer', 'postcode', 'new_build'],\n",
    "    parse_dates=['date_of_transfer']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c873c7-0438-4ffd-a38a-f1f3f94cc09d",
   "metadata": {
    "tags": []
   },
   "source": [
    "For the analysis, we will need counts by month by postcode. We can calculate these already and save space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9f54b1f-82a1-405d-8ff3-944d8a6104ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.42 s, sys: 851 ms, total: 7.27 s\n",
      "Wall time: 7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sales = (\n",
    "    pp\n",
    "    .assign(moy=pp['date_of_transfer'].dt.to_period('M'))\n",
    "    .query('new_build == \"Y\"')\n",
    "    .groupby(['moy', 'postcode'])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: 'new_sales'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6152d98-03b2-4419-bd77-14dabdfefb36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52e4eb-de37-4d7a-a0d2-20b65482a61a",
   "metadata": {},
   "source": [
    "Or, with `polars` (note most of the time is in building the `polars.DataFrame` object, rather than the computation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f80cd72b-f4e8-4106-9b7c-d2174d83bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.61 s, sys: 711 ms, total: 6.32 s\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import polars as pl\n",
    "\n",
    "sales_pl = (\n",
    "    pl.DataFrame(pp)\n",
    "    .lazy()\n",
    "    .with_column(\n",
    "        pl.col('date_of_transfer').dt.strftime(\"%Y-%m\").alias('moy')\n",
    "    )\n",
    "    .filter(pl.col('new_build') == 'Y')\n",
    "    .groupby(['moy', 'postcode'])\n",
    "    .agg(pl.count())\n",
    "    .rename({'count': 'new_sales'})\n",
    "    .collect()\n",
    "    .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e476a-4a03-4a27-9804-715101cb2619",
   "metadata": {},
   "source": [
    "To confirm they're the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8dad0d8e-905b-4039-99ca-27f5cf6bf0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    sales_pl\n",
    "    .set_index(['moy', 'postcode'])\n",
    "    .join(sales.set_index(['moy', 'postcode']), lsuffix='_pl')\n",
    "    .eval('new_sales_pl - new_sales')\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1e76f-eae2-43a4-a32a-8a047941a9f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a8023-dab3-4a44-a75f-ea4228551442",
   "metadata": {},
   "source": [
    "We write the table as we will need it later on in the [analysis](analysis.ipynb), once it's joined to the spatial signatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7014cc07-36dc-4407-96f2-464ba73e6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.to_parquet('/home/jovyan/data/tmp/sales_by_month_pc.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbefb24-97b9-459d-90ea-e104949b3ad5",
   "metadata": {},
   "source": [
    "## Postcode centroids\n",
    "\n",
    "Postcode locations (centroids) come from the [ONSPD](https://geoportal.statistics.gov.uk/datasets/ons::onspd-online-latest-centroids/explore?location=55.200148%2C-3.307439%2C6.80) database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52155b31-ddd4-482c-b76e-a856e82da714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-23 14:41:43--  https://geoportal.statistics.gov.uk/datasets/2e65b9933cd9483b8724760f27968a48_0.csv\n",
      "Resolving geoportal.statistics.gov.uk (geoportal.statistics.gov.uk)... 44.207.123.71, 3.219.120.199, 34.193.115.202\n",
      "Connecting to geoportal.statistics.gov.uk (geoportal.statistics.gov.uk)|44.207.123.71|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘/home/jovyan/data/tmp/postcodes.csv’\n",
      "\n",
      "/home/jovyan/data/t     [   <=>              ]   1.10G  15.1MB/s    in 50s     \n",
      "\n",
      "2022-12-23 14:42:33 (22.6 MB/s) - ‘/home/jovyan/data/tmp/postcodes.csv’ saved [1186245382]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget \\\n",
    "    https://geoportal.statistics.gov.uk/datasets/2e65b9933cd9483b8724760f27968a48_0.csv \\\n",
    "    -O $pc_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bfaea-0055-4dfe-99c0-d57004d954ed",
   "metadata": {},
   "source": [
    "We read in parallel only the columns we need and drop rows with any missing value as we need postcodes for which we have the three features (i.e., IDs and location coordinates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29319149-c5d2-483f-a4c0-25eb2e7a7ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 535 ms, sys: 130 ms, total: 665 ms\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pcs = ddf.read_csv(\n",
    "    pc_p,\n",
    "    usecols=['PCD', 'OSEAST1M', 'OSNRTH1M'],\n",
    "    assume_missing=True\n",
    ").dropna().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69518fc-c9a6-48ad-aa49-18789c38c087",
   "metadata": {},
   "source": [
    "We generate the point geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfbbc80c-31c1-439b-bced-c87848a89523",
   "metadata": {},
   "outputs": [],
   "source": [
    "xys = geopandas.points_from_xy(\n",
    "    pcs['OSEAST1M'], pcs['OSNRTH1M']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb4d12-1f8a-4a2d-aeab-09f008de481a",
   "metadata": {},
   "source": [
    "We can now build the geo-table with the point geometries of all available postcodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3625d720-8ada-4a92-a2c5-9f66877a69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_pts = (\n",
    "    geopandas.GeoDataFrame(\n",
    "        pcs[['PCD']], geometry=xys\n",
    "    ).set_crs(epsg=27700)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b9c3c2-c984-43dd-a902-9d18732ec0f2",
   "metadata": {},
   "source": [
    "The ONSPD appears to contain postcodes expressed with a space in between and without:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3367f83c-97f3-47a1-b98d-7fae71ccbcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCD</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB1 0AA</td>\n",
       "      <td>POINT (385386.000 801193.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PCD                       geometry\n",
       "0  AB1 0AA  POINT (385386.000 801193.000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_pts[pc_pts['PCD'].str.contains(' ')].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dbf1f20-54c8-43a3-a0d0-5e7ad1287748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCD</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>AB101AA</td>\n",
       "      <td>POINT (394251.000 806376.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PCD                       geometry\n",
       "2655  AB101AA  POINT (394251.000 806376.000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_pts[~pc_pts['PCD'].str.contains(' ')].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13fb86-ce43-4a20-b561-b44f78b7ac54",
   "metadata": {},
   "source": [
    "While the postcodes in the Land Registry all are expressed with a space (with the exception of an `UNKNOWN` instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6bed9b-f7dc-40be-8e90-6d9a13a69ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201210    UNKNOWN\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_upcs = pandas.Series(sales['postcode'].unique())\n",
    "lr_upcs[~lr_upcs.str.contains(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef92d46-72bb-457d-b534-b0dd65324415",
   "metadata": {},
   "source": [
    "To connect the two tables, we join them only after removing spaces in both sets of postcodes (which finds a geometry for the vast majority of postcodes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f98b8b9b-7e42-4f9e-b776-bbdea0c1b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 284126 entries, 0 to 284125\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype   \n",
      "---  ------    --------------   -----   \n",
      " 0   lr_upc    284126 non-null  object  \n",
      " 1   PCD       283932 non-null  object  \n",
      " 2   geometry  283932 non-null  geometry\n",
      "dtypes: geometry(1), object(2)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "j = geopandas.GeoDataFrame(\n",
    "    pandas.DataFrame(\n",
    "        {'lr_upc': lr_upcs, 'jlr_upc': lr_upcs.str.replace(' ', '')}\n",
    "    )\n",
    "    .join(\n",
    "        pc_pts.assign(jPCD=pc_pts['PCD'].str.replace(' ', '')).set_index('jPCD'), \n",
    "        on='jlr_upc',\n",
    "        how='left'\n",
    "    )\n",
    "    .drop(columns=['jlr_upc'])\n",
    ").set_crs(pc_pts.crs)\n",
    "\n",
    "j.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335629bb-3a49-4d0c-9acf-7c4d0743f5b0",
   "metadata": {},
   "source": [
    "We write this to disk to be able to join it to spatial signature types [on a GPU](gpu_spatial_join.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aa2cb83-784a-48ef-93cd-d7047d5c7a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3543616/936528254.py:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  j.to_parquet('/home/jovyan/data/tmp/postcode_pts.pq')\n"
     ]
    }
   ],
   "source": [
    "j.to_parquet('/home/jovyan/data/tmp/postcode_pts.pq')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
